### 7) üñºÔ∏è Buscador visual por similitud (10)

# **Objetivo:** Dada una imagen, encontrar similares por embeddings o etiquetas.

# **M√≠nimos**
# - Dataset local (assets/).
# - Indexaci√≥n por embeddings/tags.
# - Consulta: top-k similares con score.

# **Arquitectura**
# - Preproceso ‚Üí embeddings (CLIP/Vision) ‚Üí vector store ‚Üí similitud ‚Üí grid UI.

# **APIs/Modelos**
# - Azure: Vision (tags) + (opcional) embeddings con Azure OpenAI (CLIP-like).
# - Alternativas: HF openai/clip-vit-base-patch32; Google Vision labels.

# **P√°ginas**
# - ‚ÄúIndexar‚Äù.
# - ‚ÄúBuscar‚Äù.

# **Ampliaciones**
# - Filtro por etiquetas.
# - B√∫squeda por texto (‚Äúplaya al atardecer‚Äù).

import requests, os, sys
from dotenv import load_dotenv
import streamlit as st

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if BASE_DIR not in sys.path:
    sys.path.append(BASE_DIR)
    
from controller.IndexImageController import IndexImagenesController

# Carga las variables del archivo .env (solo en local)
load_dotenv()

# üîê Configuraci√≥n Azure Speech
SPEECH_KEY = os.getenv("SPEECH_KEY")
REGION = os.getenv("REGION")

st.title("Proyecto Final:üñºÔ∏è Buscador visual por similitud")

col1, col2 = st.columns(2)

# Configuraciones de API de: 
subscription_key = os.getenv("SBSCRIPTION_KEY")
endpoint = os.getenv("ENDPOINT")

# Request headers.
headers = {
    'Content-Type': 'application/octet-stream',
    'Ocp-Apim-Subscription-Key': subscription_key,
}

# Request parameters. All of them are optional.
params = {
    'visualFeatures': 'tags',
    'language': 'es',
}



# - 1 Indexar imagenes de assets/
# Recorrer la carpeta y leer las rutas de las im√°genes.
with st.spinner('üîç Indexando im√°genes, por favor espera...'):
    try:
        indexador = IndexImagenesController(
            assets_dir="assets",
            output_file="image_index.json"
        )
        indexador.crear_index()
    except Exception as e:
        st.error(f"‚ùå Error al indexar im√°genes: {e}")



# TODO:
# - 2 Obtener embeddings o tags
# Usar modelos preentrenados que generan vectores de caracter√≠sticas visuales, por ejemplo:
# CLIP (de OpenAI, v√≠a open_clip o transformers)
# ResNet50 (desde torchvision.models)
# ViT (Vision Transformer)
# Cada imagen ‚Üí un vector num√©rico (embedding).


# TODO:
# - 3 Almacenar en vector DB (FAISS u otra)
# Utilizar FAISS para indexar los embeddings y permitir b√∫squedas r√°pidas por similitud.


# TODO:
# - 4 Utilizar top-k similitud
# FAISS te permite buscar los k m√°s similares


# TODO:
# - 5 Implementar b√∫squeda por similitud
# Pasar una imagen de consulta, generar su embedding y comparar con FAISS.


# TODO:
# - 6 Mostrar resultados en grid UI
# Usar Streamlit para mostrar las im√°genes similares en una cuadr√≠cula.


st.markdown("---")
st.markdown("¬© 2025 - Proyecto de Programaci√≥n de Inteligencia Artificial: Buscador visual por similitud")
st.markdown("Desarrollado por [jbotgil] [https://github.com/jbotgil]")